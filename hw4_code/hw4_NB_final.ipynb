{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_OTcE_B9Kxh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "670fa0cf-e510-48ce-fd4d-5790d9ada865"
      },
      "source": [
        "!pip install -U scikit-learn"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.22.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.1.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViEYQEM0DoWe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96bd3f8e-2c40-43bb-ea5b-af088ee00815"
      },
      "source": [
        "!tar -xvf languageID.tgz"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "languageID/\n",
            "languageID/e0.txt\n",
            "languageID/e10.txt\n",
            "languageID/e11.txt\n",
            "languageID/e12.txt\n",
            "languageID/e13.txt\n",
            "languageID/e14.txt\n",
            "languageID/e15.txt\n",
            "languageID/e16.txt\n",
            "languageID/e17.txt\n",
            "languageID/e18.txt\n",
            "languageID/e19.txt\n",
            "languageID/e1.txt\n",
            "languageID/e2.txt\n",
            "languageID/e3.txt\n",
            "languageID/e4.txt\n",
            "languageID/e5.txt\n",
            "languageID/e6.txt\n",
            "languageID/e7.txt\n",
            "languageID/e8.txt\n",
            "languageID/e9.txt\n",
            "languageID/j0.txt\n",
            "languageID/j10.txt\n",
            "languageID/j11.txt\n",
            "languageID/j12.txt\n",
            "languageID/j13.txt\n",
            "languageID/j14.txt\n",
            "languageID/j15.txt\n",
            "languageID/j16.txt\n",
            "languageID/j17.txt\n",
            "languageID/j18.txt\n",
            "languageID/j19.txt\n",
            "languageID/j1.txt\n",
            "languageID/j2.txt\n",
            "languageID/j3.txt\n",
            "languageID/j4.txt\n",
            "languageID/j5.txt\n",
            "languageID/j6.txt\n",
            "languageID/j7.txt\n",
            "languageID/j8.txt\n",
            "languageID/j9.txt\n",
            "languageID/s0.txt\n",
            "languageID/s1.txt\n",
            "languageID/s10.txt\n",
            "languageID/s11.txt\n",
            "languageID/s12.txt\n",
            "languageID/s13.txt\n",
            "languageID/s14.txt\n",
            "languageID/s15.txt\n",
            "languageID/s16.txt\n",
            "languageID/s17.txt\n",
            "languageID/s18.txt\n",
            "languageID/s19.txt\n",
            "languageID/s2.txt\n",
            "languageID/s3.txt\n",
            "languageID/s4.txt\n",
            "languageID/s5.txt\n",
            "languageID/s6.txt\n",
            "languageID/s7.txt\n",
            "languageID/s8.txt\n",
            "languageID/s9.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkGtHnMID239"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import numpy as np"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iv2vcSQX4Wry"
      },
      "source": [
        "**Prior Probability:**\n",
        "\n",
        "Treating texts 0-9 from each language as training set, we have 30 documents in total. So $\\hat{p}(y=e)=\\frac{1}{3}$, $\\hat{p}(y=s)=\\frac{1}{3}$ and $\\hat{p}(y=j)=\\frac{1}{3}$. Using additive smoothing, we have the probabilities as, \n",
        "\n",
        "$\\hat{p}(y=e)= \\frac{10 + 0.5}{30 + 3*0.5}=\\frac{11.5}{31.5}=0.33$\n",
        "$\\hat{p}(y=s)= \\frac{10 + 0.5}{30 + 3*0.5}=\\frac{11.5}{31.5}=0.33$\n",
        "$\\hat{p}(y=j)= \\frac{10 + 0.5}{30 + 3*0.5}=\\frac{11.5}{31.5}=0.33$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BD4pxuAOpgFx"
      },
      "source": [
        "character_list = [' ','a', 'b', 'c', 'd', 'e', 'f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
        "char_probs_dict_en = {}\n",
        "char_probs_dict_jap = {}\n",
        "char_probs_dict_s = {}\n",
        "\n",
        "char_count_test_en = {}\n",
        "char_count_test_jap = {}\n",
        "char_count_test_s = {}\n",
        "\n",
        "for char in character_list:\n",
        "  char_probs_dict_en[char] = 0\n",
        "  char_probs_dict_jap[char] = 0\n",
        "  char_probs_dict_s[char] = 0\n",
        "\n",
        "  char_count_test_en[char] = 0\n",
        "  char_count_test_jap[char] = 0\n",
        "  char_count_test_s[char] = 0\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5fOQi77rRdj"
      },
      "source": [
        "def reinitialize_dict(char_dict):\n",
        "  for key in char_dict.keys():\n",
        "    char_dict[key] = 0\n",
        "\n",
        "def additive_smoothing(char_dict, char_count_sum):\n",
        "  for key in char_dict.keys():\n",
        "    if char_dict[key] == 0.0:\n",
        "      char_dict[key] = 0.5/(char_count_sum+13.5)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8wYEp6sOYNL"
      },
      "source": [
        "#Get character count in set of files\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ewu2b1765d5W"
      },
      "source": [
        "def get_char_count(file_list):\n",
        "  char_count = {}\n",
        "  for filename in file_list:\n",
        "    with open(filename) as f:\n",
        "      while True:\n",
        "        c = f.read(1)\n",
        "        if not c:\n",
        "          break\n",
        "        if c!='\\n':\n",
        "          if c not in char_count:\n",
        "            char_count[c] = 1\n",
        "          else:\n",
        "            char_count[c] +=1\n",
        "  return char_count"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vo4ikhJF5mZK"
      },
      "source": [
        "#Class Conditional Probability of English\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vb0-yYeM4V6H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed8491c7-ddce-4373-dde2-9421ccac9a06"
      },
      "source": [
        "en_file_list = []\n",
        "for i in range(0,10):\n",
        "   en_file_list.append(\"languageID/e\"+str(i)+\".txt\")\n",
        "print(en_file_list)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['languageID/e0.txt', 'languageID/e1.txt', 'languageID/e2.txt', 'languageID/e3.txt', 'languageID/e4.txt', 'languageID/e5.txt', 'languageID/e6.txt', 'languageID/e7.txt', 'languageID/e8.txt', 'languageID/e9.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0I5uUleOhGU"
      },
      "source": [
        "#Use vectorizer to get frequency count and features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmTsfQfP8e4h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd75da43-1e2b-44d7-fd6f-ea0494e45da6"
      },
      "source": [
        "vectorizer_en = CountVectorizer(analyzer='char',input=\"filename\")\n",
        "char_vector_en = vectorizer_en.fit_transform(en_file_list)\n",
        "print(vectorizer_en.get_feature_names_out())\n",
        "char_array_en = char_vector_en.toarray()\n",
        "char_count_dict = get_char_count(en_file_list)\n",
        "char_count_en = char_array_en.sum(axis=0)\n",
        "char_count_en[0]=char_count_dict[' ']\n",
        "char_probs_en = (char_count_en+0.5) / (char_count_en.sum()+13.5)\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' ' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm' 'n' 'o' 'p' 'q'\n",
            " 'r' 's' 't' 'u' 'v' 'w' 'x' 'y' 'z']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXuaNCYgOocG"
      },
      "source": [
        "**`Get class conditional probabilities`**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVtORP4HOn6Y"
      },
      "source": [
        "for char, char_prob in zip(list(vectorizer_en.get_feature_names_out()), char_probs_en):\n",
        "  char_probs_dict_en[char] = char_prob\n",
        "additive_smoothing(char_probs_dict_en,char_count_en.sum())\n",
        "char_probs_en = list(char_probs_dict_en.values())"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYsTPz7Gvkh4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3955a260-da47-4a84-bd5c-4d906995a4a2"
      },
      "source": [
        "char_probs_dict_en"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ': 0.1792499586981662,\n",
              " 'a': 0.0601685114819098,\n",
              " 'b': 0.011134974392863043,\n",
              " 'c': 0.021509995043779945,\n",
              " 'd': 0.021972575582355856,\n",
              " 'e': 0.1053692383941847,\n",
              " 'f': 0.018932760614571286,\n",
              " 'g': 0.017478936064761277,\n",
              " 'h': 0.047216256401784236,\n",
              " 'i': 0.055410540227986124,\n",
              " 'j': 0.001420783082768875,\n",
              " 'k': 0.0037336857756484387,\n",
              " 'l': 0.028977366595076822,\n",
              " 'm': 0.020518751032545846,\n",
              " 'n': 0.057921691723112505,\n",
              " 'o': 0.06446390219725756,\n",
              " 'p': 0.01675202378985627,\n",
              " 'q': 0.0005617049396993227,\n",
              " 'r': 0.053824549810011564,\n",
              " 's': 0.06618205848339666,\n",
              " 't': 0.08012555757475633,\n",
              " 'u': 0.026664463902197257,\n",
              " 'v': 0.009284652238559392,\n",
              " 'w': 0.015496448042293078,\n",
              " 'x': 0.001156451346439782,\n",
              " 'y': 0.013844374690236246,\n",
              " 'z': 0.0006277878737815959}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bLeuq5mOwe5"
      },
      "source": [
        "# Class conditional probabilities of Japanese"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axmYWQkv-lVs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "193d5748-1105-4c77-a9f1-c9f25e7f6e03"
      },
      "source": [
        "jap_file_list = []\n",
        "for i in range(0,10):\n",
        "   jap_file_list.append(\"languageID/j\"+str(i)+\".txt\")\n",
        "print(jap_file_list)\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['languageID/j0.txt', 'languageID/j1.txt', 'languageID/j2.txt', 'languageID/j3.txt', 'languageID/j4.txt', 'languageID/j5.txt', 'languageID/j6.txt', 'languageID/j7.txt', 'languageID/j8.txt', 'languageID/j9.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yccZl-SZO1x-"
      },
      "source": [
        "#Use vectorizer to get frequency count and features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SinsMITkKPsB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4e282b5-ddd3-4c2c-c5d6-4a91879403e3"
      },
      "source": [
        "vectorizer_jap = CountVectorizer(analyzer='char',input=\"filename\")\n",
        "char_vector_jap = vectorizer_jap.fit_transform(jap_file_list)\n",
        "print(vectorizer_jap.get_feature_names_out())\n",
        "char_array_jap = char_vector_jap.toarray()\n",
        "char_count_dict = get_char_count(jap_file_list)\n",
        "char_count_jap = char_array_jap.sum(axis=0)\n",
        "char_count_jap[0] = char_count_dict[' ']\n",
        "char_probs_jap = (char_count_jap+ 0.5)  / (char_count_jap.sum() + 13.5)\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' ' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm' 'n' 'o' 'p' 'q'\n",
            " 'r' 's' 't' 'u' 'v' 'w' 'y' 'z']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jm-eZAzvPAlf"
      },
      "source": [
        "**`Get class conditional probabilities`**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8bQVRraO8UH"
      },
      "source": [
        "for char, char_prob in zip(list(vectorizer_jap.get_feature_names_out()), char_probs_jap):\n",
        "  char_probs_dict_jap[char] = char_prob\n",
        "additive_smoothing(char_probs_dict_jap,char_count_en.sum())\n",
        "char_probs_jap = list(char_probs_dict_jap.values())"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTIGvtwW7lb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aae3365d-26f2-4f5d-c9ba-8cccd81628a8"
      },
      "source": [
        "char_probs_dict_jap"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ': 0.12344945665466997,\n",
              " 'a': 0.1317656102589189,\n",
              " 'b': 0.010866906600510151,\n",
              " 'c': 0.005485866033054963,\n",
              " 'd': 0.01722631818022992,\n",
              " 'e': 0.06020475907613823,\n",
              " 'f': 0.003878542227191726,\n",
              " 'g': 0.014011670568503443,\n",
              " 'h': 0.03176211607673224,\n",
              " 'i': 0.09703343932352633,\n",
              " 'j': 0.0023411020650616725,\n",
              " 'k': 0.05740941332681086,\n",
              " 'l': 0.001432614696530277,\n",
              " 'm': 0.03979873510604843,\n",
              " 'n': 0.05671057688947902,\n",
              " 'o': 0.09116321324993885,\n",
              " 'p': 0.0008735455466648031,\n",
              " 'q': 0.00010482546559977637,\n",
              " 'r': 0.04280373178657535,\n",
              " 's': 0.0421747789929767,\n",
              " 't': 0.056990111464411755,\n",
              " 'u': 0.07061742199238269,\n",
              " 'v': 0.0002445927530661449,\n",
              " 'w': 0.01974212935462455,\n",
              " 'x': 3.3041467041136624e-05,\n",
              " 'y': 0.01415143785596981,\n",
              " 'z': 0.00772214263251686}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulb2Dr9ePHaA"
      },
      "source": [
        "# Class conditional probabilities of Spanish\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1rfj_J9KPxw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebc19d74-5b5f-4b67-ed82-afa2c54e1be3"
      },
      "source": [
        "span_file_list = []\n",
        "for i in range(0,10):\n",
        "   span_file_list.append(\"languageID/s\"+str(i)+\".txt\")\n",
        "print(span_file_list)\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['languageID/s0.txt', 'languageID/s1.txt', 'languageID/s2.txt', 'languageID/s3.txt', 'languageID/s4.txt', 'languageID/s5.txt', 'languageID/s6.txt', 'languageID/s7.txt', 'languageID/s8.txt', 'languageID/s9.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eq5NRAqcPL4m"
      },
      "source": [
        "#Use vectorizer to get frequency count and features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qxkdv96SKP1I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35c7ebb1-d13c-4794-94ce-ee3992b1e0c0"
      },
      "source": [
        "vectorizer_s = CountVectorizer(analyzer='char',input=\"filename\")\n",
        "char_vector_s = vectorizer_s.fit_transform(span_file_list)\n",
        "print(vectorizer_s.get_feature_names_out())\n",
        "char_array_s = char_vector_s.toarray()\n",
        "char_count_dict = get_char_count(span_file_list)\n",
        "char_count_s = char_array_s.sum(axis=0)\n",
        "char_count_s[0] = char_count_dict[' ']\n",
        "char_probs_s = (char_count_s+0.5) / (char_count_s.sum() + 13.5)\n",
        "\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' ' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm' 'n' 'o' 'p' 'q'\n",
            " 'r' 's' 't' 'u' 'v' 'w' 'x' 'y' 'z']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "se1iAN7TPQUK"
      },
      "source": [
        "Get class conditional probabilities\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMV01q3jPPnd"
      },
      "source": [
        "for char, char_prob in zip(list(vectorizer_s.get_feature_names_out()), char_probs_s):\n",
        "  char_probs_dict_s[char] = char_prob\n",
        "additive_smoothing(char_probs_dict_s,char_count_en.sum())\n",
        "char_probs_s = list(char_probs_dict_s.values())"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clMlo04y7srp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db5f7d24-763d-4de6-a615-0b07bfcf45fa"
      },
      "source": [
        "char_probs_dict_s"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ': 0.16826493170115014,\n",
              " 'a': 0.10456045141993771,\n",
              " 'b': 0.008232863618143134,\n",
              " 'c': 0.03752582405722919,\n",
              " 'd': 0.039745922111559924,\n",
              " 'e': 0.1138108599796491,\n",
              " 'f': 0.00860287996053159,\n",
              " 'g': 0.0071844839813758445,\n",
              " 'h': 0.0045327001942585795,\n",
              " 'i': 0.049859702136844375,\n",
              " 'j': 0.006629459467793161,\n",
              " 'k': 0.0002775122567913416,\n",
              " 'l': 0.052943171656748174,\n",
              " 'm': 0.02580863988159477,\n",
              " 'n': 0.054176559464709693,\n",
              " 'o': 0.07249236841293824,\n",
              " 'p': 0.02426690512164287,\n",
              " 'q': 0.007677839104560451,\n",
              " 'r': 0.05929511886774999,\n",
              " 's': 0.06577040485954797,\n",
              " 't': 0.03561407295488884,\n",
              " 'u': 0.03370232185254849,\n",
              " 'v': 0.00588942678301625,\n",
              " 'w': 9.250408559711388e-05,\n",
              " 'x': 0.0024976103111220747,\n",
              " 'y': 0.007862847275754679,\n",
              " 'z': 0.0026826184823163022}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iE_xlsPPXUC"
      },
      "source": [
        "#Prediction for test file - e10.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7oSKtqGPd5Q"
      },
      "source": [
        "##Using vectorizer to get features and frequency count\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6Ka8pULMdsK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b38947e7-9a8f-4801-90bd-ce2d0a73f242"
      },
      "source": [
        "\n",
        "char_vector_en_test = vectorizer_en.transform([\"languageID/e10.txt\"])\n",
        "print(vectorizer_en.get_feature_names_out())\n",
        "char_array_en_test = char_vector_en_test.toarray()\n",
        "char_count_dict = get_char_count([\"languageID/e10.txt\"])\n",
        "char_count_en_test = char_array_en_test.sum(axis=0)\n",
        "char_count_en_test[0] = char_count_dict[' ']\n",
        "for char, char_count in zip(list(vectorizer_en.get_feature_names_out()), char_count_en_test):\n",
        "  char_count_test_en[char] = char_count\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' ' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm' 'n' 'o' 'p' 'q'\n",
            " 'r' 's' 't' 'u' 'v' 'w' 'x' 'y' 'z']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2Bq56xjPokb"
      },
      "source": [
        "###Calculate $\\hat{p}(x \\mid y=e)$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CU9-0tBoOiG0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db4090eb-5a6d-4c06-eb86-48e558f3f2c7"
      },
      "source": [
        "total_prob_en = 0\n",
        "for char_prob, char_count in zip(char_probs_en,list(char_count_test_en.values())):\n",
        "  total_prob_en += char_count * np.log(char_prob)\n",
        "  # print(np.log(char_prob))\n",
        "print(total_prob_en)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-7841.865447060634\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4QNOofFQAIe"
      },
      "source": [
        "###Calculate $\\hat{p}(x \\mid y=j)$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98vHdu5YQmWP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac49eaf2-4cef-4c74-f0e5-60ff6e753f7a"
      },
      "source": [
        "total_prob_jap = 0\n",
        "for char_prob, char_count in zip(char_probs_jap,list(char_count_test_en.values())):\n",
        "  total_prob_jap += char_count * np.log(char_prob)\n",
        "  # print(np.log(char_prob))\n",
        "print(total_prob_jap)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-8771.65676346074\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6g3rcTXQB-S"
      },
      "source": [
        "###Calculate $\\hat{p}(x \\mid y=s)$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2J6cgJgQmZA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36081e60-cd74-425e-c514-3be5bfab5a02"
      },
      "source": [
        "total_prob_s = 0\n",
        "for char_prob, char_count in zip(char_probs_s,list(char_count_test_en.values())):\n",
        "  total_prob_s += char_count * np.log(char_prob)\n",
        "  # print(np.log(char_prob))\n",
        "print(total_prob_s)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-8467.282044010557\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaveREdiuVJ-"
      },
      "source": [
        "**Posterior Probabilities**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LDNFxPgQFwa"
      },
      "source": [
        "Calculate $\\hat{p}(y=e \\mid x)$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zB3FRtsQmcI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8634b4b-0559-44d2-f695-88e56be3f07c"
      },
      "source": [
        "log_prior_en = np.log(1/3)\n",
        "log_posterior_en = total_prob_en +log_prior_en\n",
        "print(log_posterior_en)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-7842.964059349302\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mC19JuMQVgag"
      },
      "source": [
        "Calculate $\\hat{p}(y=j \\mid x)$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnwAAVTGQme8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51313cef-74a9-4449-ff6f-2f8adbeb3912"
      },
      "source": [
        "log_prior_jap = np.log(1/3)\n",
        "log_posterior_jap = total_prob_jap +log_prior_jap\n",
        "print(log_posterior_jap)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-8772.755375749408\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-mH66eFViGu"
      },
      "source": [
        "Calculate $\\hat{p}(y=s \\mid x)$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "im7Tuv7BQmh8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa1a3586-72dc-43b0-bf58-3b889332c95e"
      },
      "source": [
        "log_prior_s = np.log(1/3)\n",
        "log_posterior_s = total_prob_s +log_prior_s\n",
        "print(log_posterior_s)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-8468.380656299225\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNInsYavVl0n"
      },
      "source": [
        "Predicted label is \"english\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kstiCZrOQmla",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1945f355-80b6-447c-f914-bc5c4abc96c2"
      },
      "source": [
        "max(log_posterior_en,log_posterior_jap,log_posterior_s)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-7842.964059349302"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9Gt9IHx_Fd7"
      },
      "source": [
        "**Log to base 10**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvPu6-Ph-50m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9210d663-818a-4c9e-ad2e-75e9567fb642"
      },
      "source": [
        "total_prob_en = 0\n",
        "for char_prob, char_count in zip(char_probs_en,list(char_count_test_en.values())):\n",
        "  total_prob_en += char_count * np.log10(char_prob)\n",
        "  # print(np.log(char_prob))\n",
        "print(total_prob_en)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-3405.6788914862113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14EsLESA-53c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7c42c6d-4ea2-4a02-841e-30be142a177d"
      },
      "source": [
        "total_prob_jap = 0\n",
        "for char_prob, char_count in zip(char_probs_jap,list(char_count_test_en.values())):\n",
        "  total_prob_jap += char_count * np.log10(char_prob)\n",
        "  # print(np.log(char_prob))\n",
        "print(total_prob_jap)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-3809.482129520336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T51P48Ea-56Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "539c0752-8c7e-4c76-c70d-322129e678a5"
      },
      "source": [
        "total_prob_s = 0\n",
        "for char_prob, char_count in zip(char_probs_s,list(char_count_test_en.values())):\n",
        "  total_prob_s += char_count * np.log10(char_prob)\n",
        "  # print(np.log(char_prob))\n",
        "print(total_prob_s)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-3677.2938684322726\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vi7j2ECc-59J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d77b3e5-0b30-47ae-cad2-624eb702727b"
      },
      "source": [
        "log_prior_en = np.log10(1/3)\n",
        "log_posterior_en = total_prob_en +log_prior_en\n",
        "print(log_posterior_en)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-3406.156012740931\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pt8WZV9Y-6AC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0cba526-0127-42d9-b677-f878b1b8ca38"
      },
      "source": [
        "log_prior_jap = np.log10(1/3)\n",
        "log_posterior_jap = total_prob_jap +log_prior_jap\n",
        "print(log_posterior_jap)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-3809.959250775056\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qn5GWh9E-6Cp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a41a46c-e14a-4540-eb02-82a3cf4701da"
      },
      "source": [
        "log_prior_s = np.log10(1/3)\n",
        "log_posterior_s = total_prob_s +log_prior_s\n",
        "print(log_posterior_s)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-3677.7709896869924\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRy6Len5-6Fp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83bc4f34-9966-48fd-f7e8-3bd423db53ff"
      },
      "source": [
        "max(log_posterior_en,log_posterior_jap,log_posterior_s)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-3406.156012740931"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODy3k8y4Vpml"
      },
      "source": [
        "# Get Classification Performance - Confusion Matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaIyL9eWvGcA"
      },
      "source": [
        "def compute_en_prob(char_probs_en,char_count_en):\n",
        "  total_prob_en = 0\n",
        "  for char_prob, char_count in zip(char_probs_en,char_count_en):\n",
        "    total_prob_en += char_count * np.log10(char_prob)\n",
        "    # print(np.log(char_prob))\n",
        "  \n",
        "  print(\"Log likelihood is\" + str(total_prob_en))\n",
        "  log_prior_en = np.log10(1/3)\n",
        "  log_posterior_en = total_prob_en +log_prior_en\n",
        "  print(\"Log posterior is \"+str(log_posterior_en))\n",
        "  return log_posterior_en"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1rKRb08veTk"
      },
      "source": [
        "def compute_jap_prob(char_probs_jap, char_count_jap):\n",
        "  total_prob_jap = 0\n",
        "  for char_prob, char_count in zip(char_probs_jap,char_count_jap):\n",
        "    total_prob_jap += char_count * np.log10(char_prob)\n",
        "    # print(np.log(char_prob))\n",
        "  print(\"Log likelihood is\" + str(total_prob_jap))\n",
        "  log_prior_jap = np.log10(1/3)\n",
        "  log_posterior_jap = total_prob_jap +log_prior_jap\n",
        "  print(\"Log posterior is \"+str(log_posterior_jap))\n",
        "  return log_posterior_jap\n",
        "  "
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFfeOqU4vvX1"
      },
      "source": [
        "def compute_spanish_prob(char_probs_s, char_count_s):\n",
        "  total_prob_s = 0\n",
        "  for char_prob, char_count in zip(char_probs_s,char_count_s):\n",
        "    total_prob_s += char_count * np.log10(char_prob)\n",
        "  print(\"Log likelihood is\" + str(total_prob_s))\n",
        "  log_prior_s = np.log10(1/3)\n",
        "  log_posterior_s = total_prob_s +log_prior_s\n",
        "  print(\"Log posterior is \"+str(log_posterior_s))\n",
        "  return log_posterior_s\n",
        "\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPWOiJT5Vxfa"
      },
      "source": [
        "##Performance on English test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CCbViwjwC8j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13984e92-8c7b-46a6-b4d0-30779519e219"
      },
      "source": [
        "en_test_files = []\n",
        "count_en = 0\n",
        "count_jap = 0\n",
        "count_span = 0\n",
        "for i in range(10,20):\n",
        "  log_posteriors = []\n",
        "  reinitialize_dict(char_count_test_en)\n",
        "  char_vector_en_test = vectorizer_en.transform([\"languageID/e\"+str(i)+\".txt\"])\n",
        "  print(vectorizer_en.get_feature_names_out())\n",
        "  char_array_en_test = char_vector_en_test.toarray()\n",
        "  char_count_en_test = char_array_en_test.sum(axis=0)\n",
        "  for char, char_count in zip(list(vectorizer_en.get_feature_names_out()), char_count_en_test):\n",
        "    char_count_test_en[char] = char_count\n",
        "\n",
        "  char_count_en_test = list(char_count_test_en.values())\n",
        "\n",
        "\n",
        "\n",
        "  print(\"English\")\n",
        "  log_posteriors.append(compute_en_prob(char_probs_en,char_count_en_test))\n",
        "  print(\"Japanese\")\n",
        "  log_posteriors.append(compute_jap_prob(char_probs_jap,char_count_en_test))\n",
        "  print(\"Spanish\")\n",
        "  log_posteriors.append(compute_spanish_prob(char_probs_s,char_count_en_test))\n",
        "  print(np.argmax(log_posteriors))\n",
        "  if np.argmax(log_posteriors) == 0:\n",
        "    count_en+=1\n",
        "  elif np.argmax(log_posteriors) == 1:\n",
        "    count_jap+=1\n",
        "  else:\n",
        "    count_span+=1\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' ' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm' 'n' 'o' 'p' 'q'\n",
            " 'r' 's' 't' 'u' 'v' 'w' 'x' 'y' 'z']\n",
            "English\n",
            "Log likelihood is-3401.1996458718436\n",
            "Log posterior is -3401.6767671265634\n",
            "Japanese\n",
            "Log likelihood is-3804.031064617054\n",
            "Log posterior is -3804.508185871774\n",
            "Spanish\n",
            "Log likelihood is-3672.6498301136667\n",
            "Log posterior is -3673.1269513683865\n",
            "0\n",
            "[' ' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm' 'n' 'o' 'p' 'q'\n",
            " 'r' 's' 't' 'u' 'v' 'w' 'x' 'y' 'z']\n",
            "English\n",
            "Log likelihood is-4057.515162165417\n",
            "Log posterior is -4057.992283420137\n",
            "Japanese\n",
            "Log likelihood is-4518.057491168433\n",
            "Log posterior is -4518.534612423153\n",
            "Spanish\n",
            "Log likelihood is-4365.826788920477\n",
            "Log posterior is -4366.3039101751965\n",
            "0\n",
            "[' ' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm' 'n' 'o' 'p' 'q'\n",
            " 'r' 's' 't' 'u' 'v' 'w' 'x' 'y' 'z']\n",
            "English\n",
            "Log likelihood is-2297.698961567596\n",
            "Log posterior is -2298.176082822316\n",
            "Japanese\n",
            "Log likelihood is-2537.498548748493\n",
            "Log posterior is -2537.9756700032126\n",
            "Spanish\n",
            "Log likelihood is-2469.589668956739\n",
            "Log posterior is -2470.0667902114587\n",
            "0\n",
            "[' ' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm' 'n' 'o' 'p' 'q'\n",
            " 'r' 's' 't' 'u' 'v' 'w' 'x' 'y' 'z']\n",
            "English\n",
            "Log likelihood is-2063.484380293944\n",
            "Log posterior is -2063.961501548664\n",
            "Japanese\n",
            "Log likelihood is-2255.163044396689\n",
            "Log posterior is -2255.640165651409\n",
            "Spanish\n",
            "Log likelihood is-2252.934979122795\n",
            "Log posterior is -2253.412100377515\n",
            "0\n",
            "[' ' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm' 'n' 'o' 'p' 'q'\n",
            " 'r' 's' 't' 'u' 'v' 'w' 'x' 'y' 'z']\n",
            "English\n",
            "Log likelihood is-2035.3112148097227\n",
            "Log posterior is -2035.7883360644423\n",
            "Japanese\n",
            "Log likelihood is-2252.128221713541\n",
            "Log posterior is -2252.6053429682606\n",
            "Spanish\n",
            "Log likelihood is-2193.7472422272717\n",
            "Log posterior is -2194.2243634819915\n",
            "0\n",
            "[' ' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm' 'n' 'o' 'p' 'q'\n",
            " 'r' 's' 't' 'u' 'v' 'w' 'x' 'y' 'z']\n",
            "English\n",
            "Log likelihood is-2003.8307121917492\n",
            "Log posterior is -2004.3078334464687\n",
            "Japanese\n",
            "Log likelihood is-2193.48558532346\n",
            "Log posterior is -2193.9627065781797\n",
            "Spanish\n",
            "Log likelihood is-2160.5155536718003\n",
            "Log posterior is -2160.99267492652\n",
            "0\n",
            "[' ' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm' 'n' 'o' 'p' 'q'\n",
            " 'r' 's' 't' 'u' 'v' 'w' 'x' 'y' 'z']\n",
            "English\n",
            "Log likelihood is-3336.3751578714855\n",
            "Log posterior is -3336.8522791262053\n",
            "Japanese\n",
            "Log likelihood is-3750.700718907269\n",
            "Log posterior is -3751.177840161989\n",
            "Spanish\n",
            "Log likelihood is-3601.5352381008715\n",
            "Log posterior is -3602.0123593555913\n",
            "0\n",
            "[' ' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm' 'n' 'o' 'p' 'q'\n",
            " 'r' 's' 't' 'u' 'v' 'w' 'x' 'y' 'z']\n",
            "English\n",
            "Log likelihood is-2991.5724992793166\n",
            "Log posterior is -2992.0496205340364\n",
            "Japanese\n",
            "Log likelihood is-3309.470595368051\n",
            "Log posterior is -3309.9477166227707\n",
            "Spanish\n",
            "Log likelihood is-3198.4857210649166\n",
            "Log posterior is -3198.9628423196364\n",
            "0\n",
            "[' ' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm' 'n' 'o' 'p' 'q'\n",
            " 'r' 's' 't' 'u' 'v' 'w' 'x' 'y' 'z']\n",
            "English\n",
            "Log likelihood is-1999.2346555799202\n",
            "Log posterior is -1999.7117768346397\n",
            "Japanese\n",
            "Log likelihood is-2208.3149667848784\n",
            "Log posterior is -2208.792088039598\n",
            "Spanish\n",
            "Log likelihood is-2114.8057126088574\n",
            "Log posterior is -2115.2828338635773\n",
            "0\n",
            "[' ' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm' 'n' 'o' 'p' 'q'\n",
            " 'r' 's' 't' 'u' 'v' 'w' 'x' 'y' 'z']\n",
            "English\n",
            "Log likelihood is-722.1156095745638\n",
            "Log posterior is -722.5927308292835\n",
            "Japanese\n",
            "Log likelihood is-792.8834215244741\n",
            "Log posterior is -793.3605427791938\n",
            "Spanish\n",
            "Log likelihood is-756.8568295388397\n",
            "Log posterior is -757.3339507935594\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0P415aGQzQir",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e9c0881-47f6-4ef9-e4af-f5a15d315ee8"
      },
      "source": [
        "print(count_en)\n",
        "print(count_jap)\n",
        "print(count_span)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n",
            "0\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8JuxelPV21x"
      },
      "source": [
        "**All english test documents are labeled \"English\"**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsXxXCNaV74n"
      },
      "source": [
        "##Performance on Japanese test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNTLfFqQwfUS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "027a97df-6135-46ec-8d21-fdbca9862606"
      },
      "source": [
        "\n",
        "\n",
        "count_en = 0\n",
        "count_jap = 0\n",
        "count_span = 0\n",
        "for i in range(10,20):\n",
        "  log_posteriors = []\n",
        "  reinitialize_dict(char_count_test_jap)\n",
        "  char_vector_jap_test = vectorizer_jap.fit_transform([\"languageID/j\"+str(i)+\".txt\"])\n",
        "  print(vectorizer_jap.get_feature_names_out())\n",
        "  char_array_jap_test = char_vector_jap_test.toarray()\n",
        "  char_count_jap_test = char_array_jap_test.sum(axis=0)\n",
        "\n",
        "  for char, char_count in zip(list(vectorizer_jap.get_feature_names_out()), char_count_jap_test):\n",
        "    char_count_test_jap[char] = char_count\n",
        "\n",
        "  char_count_jap_test = list(char_count_test_jap.values())\n",
        "\n",
        "\n",
        "  print(\"English\")\n",
        "  log_posteriors.append(compute_en_prob(char_probs_en,char_count_jap_test))\n",
        "  print(\"Japanese\")\n",
        "  log_posteriors.append(compute_jap_prob(char_probs_jap,char_count_jap_test))\n",
        "  print(\"Spanish\")\n",
        "  log_posteriors.append(compute_spanish_prob(char_probs_s,char_count_jap_test))\n",
        "  print(np.argmax(log_posteriors))\n",
        "  if np.argmax(log_posteriors) == 0:\n",
        "    count_en+=1\n",
        "  elif np.argmax(log_posteriors) == 1:\n",
        "    count_jap+=1\n",
        "  else:\n",
        "    count_span+=1\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' ' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm' 'n' 'o' 'r' 's'\n",
            " 't' 'u' 'v' 'w' 'y' 'z']\n",
            "English\n",
            "Log likelihood is-1980.5736122302806\n",
            "Log posterior is -1981.0507334850001\n",
            "Japanese\n",
            "Log likelihood is-1803.9286991222164\n",
            "Log posterior is -1804.405820376936\n",
            "Spanish\n",
            "Log likelihood is-2180.9279016744276\n",
            "Log posterior is -2181.4050229291474\n",
            "1\n",
            "[' ' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'm' 'n' 'o' 'r' 's' 't'\n",
            " 'u' 'w' 'y' 'z']\n",
            "English\n",
            "Log likelihood is-2005.4666282260337\n",
            "Log posterior is -2005.9437494807532\n",
            "Japanese\n",
            "Log likelihood is-1793.3103962363818\n",
            "Log posterior is -1793.7875174911014\n",
            "Spanish\n",
            "Log likelihood is-2202.608825036029\n",
            "Log posterior is -2203.085946290749\n",
            "1\n",
            "[' ' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'm' 'n' 'o' 'r' 's' 't'\n",
            " 'u' 'w' 'y' 'z']\n",
            "English\n",
            "Log likelihood is-1664.5049729603352\n",
            "Log posterior is -1664.9820942150548\n",
            "Japanese\n",
            "Log likelihood is-1499.0076728675476\n",
            "Log posterior is -1499.4847941222672\n",
            "Spanish\n",
            "Log likelihood is-1818.0878168022778\n",
            "Log posterior is -1818.5649380569973\n",
            "1\n",
            "[' ' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'm' 'n' 'o' 'p' 'r' 's'\n",
            " 't' 'u' 'v' 'w' 'y' 'z']\n",
            "English\n",
            "Log likelihood is-2103.605438504558\n",
            "Log posterior is -2104.082559759278\n",
            "Japanese\n",
            "Log likelihood is-1892.0412699718033\n",
            "Log posterior is -1892.518391226523\n",
            "Spanish\n",
            "Log likelihood is-2307.5532403045827\n",
            "Log posterior is -2308.0303615593025\n",
            "1\n",
            "[' ' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'm' 'n' 'o' 'r' 's' 't'\n",
            " 'u' 'w' 'y' 'z']\n",
            "English\n",
            "Log likelihood is-2153.6868519248915\n",
            "Log posterior is -2154.1639731796113\n",
            "Japanese\n",
            "Log likelihood is-1912.961246676547\n",
            "Log posterior is -1913.4383679312666\n",
            "Spanish\n",
            "Log likelihood is-2330.8102667855537\n",
            "Log posterior is -2331.2873880402735\n",
            "1\n",
            "[' ' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm' 'n' 'o' 'r' 's'\n",
            " 't' 'u' 'w' 'y' 'z']\n",
            "English\n",
            "Log likelihood is-1676.8683250373135\n",
            "Log posterior is -1677.345446292033\n",
            "Japanese\n",
            "Log likelihood is-1540.3761688674024\n",
            "Log posterior is -1540.853290122122\n",
            "Spanish\n",
            "Log likelihood is-1831.5127555131503\n",
            "Log posterior is -1831.9898767678699\n",
            "1\n",
            "[' ' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'k' 'l' 'm' 'n' 'o' 'p' 'r' 's'\n",
            " 't' 'u' 'w' 'y' 'z']\n",
            "English\n",
            "Log likelihood is-1933.3931359351616\n",
            "Log posterior is -1933.8702571898812\n",
            "Japanese\n",
            "Log likelihood is-1741.0788596311725\n",
            "Log posterior is -1741.555980885892\n",
            "Spanish\n",
            "Log likelihood is-2111.5922832393694\n",
            "Log posterior is -2112.069404494089\n",
            "1\n",
            "[' ' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'm' 'n' 'o' 'p' 'r' 's'\n",
            " 't' 'u' 'w' 'y' 'z']\n",
            "English\n",
            "Log likelihood is-2096.834424478892\n",
            "Log posterior is -2097.3115457336116\n",
            "Japanese\n",
            "Log likelihood is-1908.718521916803\n",
            "Log posterior is -1909.1956431715225\n",
            "Spanish\n",
            "Log likelihood is-2292.616076549437\n",
            "Log posterior is -2293.0931978041567\n",
            "1\n",
            "[' ' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'm' 'n' 'o' 'r' 's' 't'\n",
            " 'u' 'w' 'y' 'z']\n",
            "English\n",
            "Log likelihood is-1876.6992381508333\n",
            "Log posterior is -1877.1763594055528\n",
            "Japanese\n",
            "Log likelihood is-1671.9106357884666\n",
            "Log posterior is -1672.3877570431862\n",
            "Spanish\n",
            "Log likelihood is-2051.4990881263775\n",
            "Log posterior is -2051.9762093810973\n",
            "1\n",
            "[' ' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm' 'n' 'o' 'r' 's'\n",
            " 't' 'u' 'w' 'y' 'z']\n",
            "English\n",
            "Log likelihood is-1862.593471250682\n",
            "Log posterior is -1863.0705925054015\n",
            "Japanese\n",
            "Log likelihood is-1691.820214444937\n",
            "Log posterior is -1692.2973356996565\n",
            "Spanish\n",
            "Log likelihood is-1996.8325311340507\n",
            "Log posterior is -1997.3096523887702\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXk34P-v0ORK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08635b06-c138-400f-d53c-03d6954b5f49"
      },
      "source": [
        "print(count_en)\n",
        "print(count_jap)\n",
        "print(count_span)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "10\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bu0CpMSqV-7A"
      },
      "source": [
        "**All files in Japanese test set are labeled Japanese**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0AhDxhkWDMj"
      },
      "source": [
        "##Performance on Spanish test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAOnpS0RwqhC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03676cd4-f680-4253-bf11-9fc9ce1bb344"
      },
      "source": [
        "vectorizer_test_s = CountVectorizer(analyzer='char',input=\"filename\")\n",
        "\n",
        "count_en = 0\n",
        "count_jap = 0\n",
        "count_span = 0\n",
        "for i in range(10,20):\n",
        "  log_posteriors = []\n",
        "  reinitialize_dict(char_count_test_en)\n",
        "  char_vector_s_test = vectorizer_test_s.fit_transform([\"languageID/s\"+str(i)+\".txt\"])\n",
        "  print(vectorizer_test_s.get_feature_names_out())\n",
        "  char_array_s_test = char_vector_s_test.toarray()\n",
        "  char_count_s_test = char_array_s_test.sum(axis=0)\n",
        "\n",
        "  for char, char_count in zip(list(vectorizer_s.get_feature_names_out()), char_count_s_test):\n",
        "    char_count_test_s[char] = char_count\n",
        "  \n",
        "  char_count_s_test = list(char_count_test_s.values())\n",
        "\n",
        "  \n",
        "  print(\"English\")\n",
        "  log_posteriors.append(compute_en_prob(char_probs_en,char_count_s_test))\n",
        "  print(\"Japanese\")\n",
        "  log_posteriors.append(compute_jap_prob(char_probs_jap,char_count_s_test))\n",
        "  print(\"Spanish\")\n",
        "  log_posteriors.append(compute_spanish_prob(char_probs_s,char_count_s_test))\n",
        "  print(np.argmax(log_posteriors))\n",
        "  if np.argmax(log_posteriors) == 0:\n",
        "    count_en+=1\n",
        "  elif np.argmax(log_posteriors) == 1:\n",
        "    count_jap+=1\n",
        "  else:\n",
        "    count_span+=1\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' ' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm' 'n' 'o' 'p' 'q'\n",
            " 'r' 's' 't' 'u' 'v' 'x' 'y' 'z']\n",
            "English\n",
            "Log likelihood is-2148.8904120418783\n",
            "Log posterior is -2149.367533296598\n",
            "Japanese\n",
            "Log likelihood is-2417.077772191373\n",
            "Log posterior is -2417.5548934460926\n",
            "Spanish\n",
            "Log likelihood is-2050.1735065543876\n",
            "Log posterior is -2050.6506278091074\n",
            "2\n",
            "[' ' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'l' 'm' 'n' 'o' 'p' 'q' 'r'\n",
            " 's' 't' 'u' 'v' 'x' 'y' 'z']\n",
            "English\n",
            "Log likelihood is-879.9636967825646\n",
            "Log posterior is -880.4408180372843\n",
            "Japanese\n",
            "Log likelihood is-909.3125388149\n",
            "Log posterior is -909.7896600696197\n",
            "Spanish\n",
            "Log likelihood is-869.9701404630113\n",
            "Log posterior is -870.447261717731\n",
            "2\n",
            "[' ' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'l' 'm' 'n' 'o' 'p' 'q' 'r'\n",
            " 's' 't' 'u' 'v' 'x' 'y' 'z']\n",
            "English\n",
            "Log likelihood is-2794.590115006536\n",
            "Log posterior is -2795.067236261256\n",
            "Japanese\n",
            "Log likelihood is-2946.6848327038565\n",
            "Log posterior is -2947.1619539585763\n",
            "Spanish\n",
            "Log likelihood is-2723.1922236392184\n",
            "Log posterior is -2723.669344893938\n",
            "2\n",
            "[' ' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'l' 'm' 'n' 'o' 'p' 'q' 'r'\n",
            " 's' 't' 'u' 'v' 'x' 'y' 'z']\n",
            "English\n",
            "Log likelihood is-1370.625433081451\n",
            "Log posterior is -1371.1025543361707\n",
            "Japanese\n",
            "Log likelihood is-1411.0440362245706\n",
            "Log posterior is -1411.5211574792902\n",
            "Spanish\n",
            "Log likelihood is-1354.9896093101306\n",
            "Log posterior is -1355.4667305648502\n",
            "2\n",
            "[' ' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'l' 'm' 'n' 'o' 'p' 'q' 'r'\n",
            " 's' 't' 'u' 'v' 'w' 'x' 'y' 'z']\n",
            "English\n",
            "Log likelihood is-2501.0692379884\n",
            "Log posterior is -2501.5463592431197\n",
            "Japanese\n",
            "Log likelihood is-2636.2153863688904\n",
            "Log posterior is -2636.6925076236103\n",
            "Spanish\n",
            "Log likelihood is-2406.6498097952026\n",
            "Log posterior is -2407.1269310499224\n",
            "2\n",
            "[' ' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'l' 'm' 'n' 'o' 'p' 'q' 'r'\n",
            " 's' 't' 'u' 'v' 'x' 'y' 'z']\n",
            "English\n",
            "Log likelihood is-2157.700571693701\n",
            "Log posterior is -2158.177692948421\n",
            "Japanese\n",
            "Log likelihood is-2249.8366046433634\n",
            "Log posterior is -2250.3137258980832\n",
            "Spanish\n",
            "Log likelihood is-2123.8727996336875\n",
            "Log posterior is -2124.3499208884073\n",
            "2\n",
            "[' ' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm' 'n' 'o' 'p' 'q'\n",
            " 'r' 's' 't' 'u' 'v' 'x' 'y' 'z']\n",
            "English\n",
            "Log likelihood is-2084.163819325406\n",
            "Log posterior is -2084.640940580126\n",
            "Japanese\n",
            "Log likelihood is-2341.6616555504875\n",
            "Log posterior is -2342.1387768052073\n",
            "Spanish\n",
            "Log likelihood is-2003.8096471212373\n",
            "Log posterior is -2004.2867683759569\n",
            "2\n",
            "[' ' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'l' 'm' 'n' 'o' 'p' 'q' 'r'\n",
            " 's' 't' 'u' 'v' 'x' 'y' 'z']\n",
            "English\n",
            "Log likelihood is-2576.773008373201\n",
            "Log posterior is -2577.2501296279206\n",
            "Japanese\n",
            "Log likelihood is-2714.06258223505\n",
            "Log posterior is -2714.5397034897696\n",
            "Spanish\n",
            "Log likelihood is-2526.647015476529\n",
            "Log posterior is -2527.1241367312487\n",
            "2\n",
            "[' ' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm' 'n' 'o' 'p' 'q'\n",
            " 'r' 's' 't' 'u' 'v' 'w' 'x' 'y' 'z']\n",
            "English\n",
            "Log likelihood is-2395.6112284527658\n",
            "Log posterior is -2396.0883497074856\n",
            "Japanese\n",
            "Log likelihood is-2676.400993155594\n",
            "Log posterior is -2676.8781144103136\n",
            "Spanish\n",
            "Log likelihood is-2291.005547140252\n",
            "Log posterior is -2291.482668394972\n",
            "2\n",
            "[' ' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'l' 'm' 'n' 'o' 'p' 'q' 'r'\n",
            " 's' 't' 'u' 'v' 'x' 'y' 'z']\n",
            "English\n",
            "Log likelihood is-1724.8500077123908\n",
            "Log posterior is -1725.3271289671104\n",
            "Japanese\n",
            "Log likelihood is-1782.8045307266136\n",
            "Log posterior is -1783.2816519813332\n",
            "Spanish\n",
            "Log likelihood is-1685.4428013186712\n",
            "Log posterior is -1685.9199225733907\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0A068Www48E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63a3789b-b97b-4bf8-bece-c26057817999"
      },
      "source": [
        "print(count_en)\n",
        "print(count_jap)\n",
        "print(count_span)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n",
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuLAMxIqWHeG"
      },
      "source": [
        "**All Spanish documents are labeled Spanish**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjkkaviaWLnD"
      },
      "source": [
        "##Prediction on jumbled test document - e10.txt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxQKAM2jWKyO"
      },
      "source": [
        "import random\n",
        "lines_jumbled = ''\n",
        "lines = open('languageID/e10.txt').readlines()\n",
        "for line in lines:\n",
        "  l = list(line)\n",
        "  random.shuffle(l)\n",
        "  lines_jumbled+=''.join(l)\n",
        "\n",
        "open('languageID/jumblede10.txt', 'w').writelines(lines_jumbled)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzvuK8juWb6m",
        "outputId": "2bceb00b-628a-4bda-8f93-175c1561b755"
      },
      "source": [
        "\n",
        "char_vector_en_test = vectorizer_en.transform([\"languageID/jumblede10.txt\"])\n",
        "print(vectorizer_en.get_feature_names_out())\n",
        "char_array_en_test = char_vector_en_test.toarray()\n",
        "char_count_dict = get_char_count([\"languageID/jumblede10.txt\"])\n",
        "char_count_en_test = char_array_en_test.sum(axis=0)\n",
        "char_count_en_test[0] = char_count_dict[' ']\n",
        "for char, char_count in zip(list(vectorizer_en.get_feature_names_out()), char_count_en_test):\n",
        "  char_count_test_en[char] = char_count\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' ' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm' 'n' 'o' 'p' 'q'\n",
            " 'r' 's' 't' 'u' 'v' 'w' 'x' 'y' 'z']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84z7WZwiWb6x",
        "outputId": "d46fa7ad-f7a2-4cf0-b984-4b110ebb63d2"
      },
      "source": [
        "total_prob_en = 0\n",
        "for char_prob, char_count in zip(char_probs_en,list(char_count_test_en.values())):\n",
        "  total_prob_en += char_count * np.log(char_prob)\n",
        "  # print(np.log(char_prob))\n",
        "print(total_prob_en)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-7841.865447060634\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlrK_J-_Wb6x",
        "outputId": "d4815a0f-60c7-4458-8ae9-1cd6b3db47c7"
      },
      "source": [
        "total_prob_jap = 0\n",
        "for char_prob, char_count in zip(char_probs_jap,list(char_count_test_en.values())):\n",
        "  total_prob_jap += char_count * np.log(char_prob)\n",
        "  # print(np.log(char_prob))\n",
        "print(total_prob_jap)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-8771.65676346074\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0XJR1vRWb6y",
        "outputId": "7fd7d08c-afc6-4c63-8176-ec4b26bfd2b7"
      },
      "source": [
        "total_prob_s = 0\n",
        "for char_prob, char_count in zip(char_probs_s,list(char_count_test_en.values())):\n",
        "  total_prob_s += char_count * np.log(char_prob)\n",
        "  # print(np.log(char_prob))\n",
        "print(total_prob_s)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-8467.282044010557\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cENB55B6Wb6y",
        "outputId": "31de36ee-95bb-40c3-9ea7-283f84f04ee7"
      },
      "source": [
        "log_prior_en = np.log(1/3)\n",
        "log_posterior_en = total_prob_en +log_prior_en\n",
        "print(log_posterior_en)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-7842.964059349302\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGRtWcDpWb6y",
        "outputId": "09498291-b29d-4cf7-bfad-ada945d8c4b4"
      },
      "source": [
        "log_prior_jap = np.log(1/3)\n",
        "log_posterior_jap = total_prob_jap +log_prior_jap\n",
        "print(log_posterior_jap)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-8772.755375749408\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_bGt5_MWb6y",
        "outputId": "dafe770f-6330-40ba-cc44-9ea9169dd77d"
      },
      "source": [
        "log_prior_s = np.log(1/3)\n",
        "log_posterior_s = total_prob_s +log_prior_s\n",
        "print(log_posterior_s)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-8468.380656299225\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SHwHoDdWb6z",
        "outputId": "42007e44-8be7-4a43-d28b-bd409e4179f5"
      },
      "source": [
        "max(log_posterior_en,log_posterior_jap,log_posterior_s)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-7842.964059349302"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqmBuyMXWwqg"
      },
      "source": [
        "Predicion is **\"English\"** - NO change in prediction"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3YW-S6mILlPe"
      },
      "execution_count": 59,
      "outputs": []
    }
  ]
}